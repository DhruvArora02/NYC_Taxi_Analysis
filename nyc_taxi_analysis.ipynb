{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NYC Taxi Analysis - Pro Databricks Project\n",
    "\n",
    "This notebook demonstrates ETL, Delta Lake, SQL queries, MLlib modeling, and visualizations in Databricks using NYC taxi data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col, to_timestamp, hour\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "spark = SparkSession.builder.appName('NYC Taxi Analysis').getOrCreate()\n",
    "\n",
    "# Load dataset into Spark DataFrame\n",
    "sample_path = 'data/taxi_trips.csv'  # <-- Make sure this file exists in /data\n",
    "df = spark.read.csv(sample_path, header=True, inferSchema=True)\n",
    "\n",
    "print('Sample Data:')\n",
    "df.show(5)\n",
    "\n",
    "# Also load into Pandas for local charting\n",
    "pdf = pd.read_csv(sample_path, parse_dates=['pickup_datetime', 'dropoff_datetime'], dayfirst=True)\n",
    "print(pdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Download large dataset from TLC (Parquet format)\n",
    "\"\"\"\n",
    "import urllib.request\n",
    "url = \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-01.parquet\"\n",
    "urllib.request.urlretrieve(url, \"data/yellow_tripdata_2024-01.parquet\")\n",
    "df_big = spark.read.parquet(\"data/yellow_tripdata_2024-01.parquet\")\n",
    "df_big.show(5)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert datetime columns in Spark\n",
    "df = df.withColumn('pickup_datetime', to_timestamp(col('pickup_datetime')))\n",
    "df = df.withColumn('dropoff_datetime', to_timestamp(col('dropoff_datetime')))\n",
    "\n",
    "# Add trip duration in minutes\n",
    "df = df.withColumn('trip_duration_min', \n",
    "                   (col('dropoff_datetime').cast('long') - col('pickup_datetime').cast('long')) / 60)\n",
    "\n",
    "df.printSchema()\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save as Delta table\n",
    "delta_path = 'data/delta/nyc_taxi'\n",
    "df.write.format('delta').mode('overwrite').save(delta_path)\n",
    "\n",
    "# Read Delta table\n",
    "df_delta = spark.read.format('delta').load(delta_path)\n",
    "df_delta.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register SQL table\n",
    "df_delta.createOrReplaceTempView('nyc_taxi')\n",
    "\n",
    "# Example SQL query\n",
    "avg_fare_by_location = spark.sql('''\n",
    "SELECT pickup_location, ROUND(AVG(fare_amount), 2) AS avg_fare\n",
    "FROM nyc_taxi\n",
    "GROUP BY pickup_location\n",
    "ORDER BY avg_fare DESC\n",
    "''')\n",
    "\n",
    "avg_fare_by_location.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization in Pandas\n",
    "pdf_chart = avg_fare_by_location.toPandas()\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='avg_fare', y='pickup_location', data=pdf_chart)\n",
    "plt.title('Average Fare by Pickup Location')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLlib - Predict fare_amount\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "features = ['passenger_count', 'trip_distance', 'trip_duration_min']\n",
    "assembler = VectorAssembler(inputCols=features, outputCol='features')\n",
    "df_ml = assembler.transform(df_delta).select('features', 'fare_amount')\n",
    "\n",
    "train, test = df_ml.randomSplit([0.8, 0.2], seed=42)\n",
    "lr = LinearRegression(featuresCol='features', labelCol='fare_amount')\n",
    "model = lr.fit(train)\n",
    "predictions = model.transform(test)\n",
    "\n",
    "predictions.select('features', 'fare_amount', 'prediction').show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
